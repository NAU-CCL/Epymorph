{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# devlog 2024-10-11\n",
    "\n",
    "_Author: Tyler Coles_\n",
    "\n",
    "Methods for group-and-aggregate on geo-series data.\n",
    "\n",
    "epymorph output data can be thought of as three-dimensional -- the axes are 1. time, 2. geospatial node, 3. simulation data values (which can include simulation state and transition information; aka compartments and events). A very common requirement in data processing is to be able to summarize the geography axis of this data. For example, computing the time-series of infections summed across all nodes, or grouping by some geographic hierarchy and combining those -- say simulating at county level but summing to state level.\n",
    "\n",
    "To determine the best approach, we generate some (suitably large) example data representing Census Tracts in four states, group by county, and sum to compute the time series for each of the data values present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scope.nodes=4202\n",
      "groups=187\n",
      "data.shape=(366, 4202, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from epymorph.geography.us_census import TractScope\n",
    "from epymorph.geography.us_tiger import get_states\n",
    "from epymorph.geography.us_geography import CensusGranularity\n",
    "\n",
    "year = 2020\n",
    "states = get_states(year).geoid[0:4]\n",
    "scope = TractScope.in_states(states, year)\n",
    "print(f\"{scope.nodes=}\")\n",
    "\n",
    "agg_operation = \"sum\"\n",
    "group_granularity = \"county\"\n",
    "groups = CensusGranularity.of(group_granularity).truncate_list(scope.node_ids)\n",
    "print(f\"groups={len(groups)}\")\n",
    "\n",
    "# Generate some dummy data\n",
    "T, N, Q = 366, scope.nodes, 6\n",
    "data = np.arange(T * N * Q).reshape((T, N, Q))\n",
    "print(f\"{data.shape=}\")\n",
    "\n",
    "data[0, 0:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: use numpy masks on a group-by-group basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 s ± 268 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "res1.shape=(366, 187, 6)\n"
     ]
    }
   ],
   "source": [
    "def apply_1(agg, scope, grouping, data):\n",
    "    match agg:\n",
    "        case \"sum\":\n",
    "            op_f = np.ma.sum\n",
    "        case \"min\":\n",
    "            op_f = np.ma.min\n",
    "        case \"max\":\n",
    "            op_f = np.ma.max\n",
    "        case x:\n",
    "            raise ValueError(x)\n",
    "\n",
    "    node_ids = scope.node_ids\n",
    "\n",
    "    T, N, Q = data.shape\n",
    "    groups = CensusGranularity.of(grouping).truncate_list(node_ids)\n",
    "\n",
    "    # For each group, create a mask then compute the aggregate\n",
    "    # and store in the group's result column.\n",
    "    result = np.empty(shape=(T, len(groups), Q), dtype=data.dtype)\n",
    "    for i, g in enumerate(groups):\n",
    "        in_group = np.char.startswith(node_ids, g)\n",
    "        group_mask = np.broadcast_to(\n",
    "            np.invert(in_group).reshape((1, N, 1)),\n",
    "            shape=(T, N, Q),\n",
    "        )\n",
    "        group_data = np.ma.masked_array(data, group_mask)\n",
    "        result[:, i, :] = op_f(group_data, axis=1, keepdims=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit apply_1(agg_operation, scope, group_granularity, data)\n",
    "res1 = apply_1(agg_operation, scope, group_granularity, data)\n",
    "print(f\"{res1.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: use numpy masks for the whole array at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.21 s ± 50.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "res2.shape=(366, 187, 6)\n"
     ]
    }
   ],
   "source": [
    "def apply_2(agg, scope, grouping, data):\n",
    "    match agg:\n",
    "        case \"sum\":\n",
    "            op_f = np.ma.sum\n",
    "        case \"min\":\n",
    "            op_f = np.ma.min\n",
    "        case \"max\":\n",
    "            op_f = np.ma.max\n",
    "        case x:\n",
    "            raise ValueError(x)\n",
    "\n",
    "    node_ids = scope.node_ids\n",
    "\n",
    "    T, N, Q = data.shape\n",
    "    groups = CensusGranularity.of(grouping).truncate_list(node_ids)\n",
    "    G = len(groups)\n",
    "\n",
    "    # For each group, create a mask then compute the aggregate\n",
    "    # and store in the group's result column.\n",
    "\n",
    "    mask = np.empty(shape=(N, G), dtype=np.bool_)\n",
    "    for j, g in enumerate(groups):\n",
    "        mask[:, j] = np.char.startswith(node_ids, g)\n",
    "    mask = np.broadcast_to(\n",
    "        np.invert(mask).reshape((1, N, G, 1)),\n",
    "        shape=(T, N, G, Q),\n",
    "    )\n",
    "\n",
    "    reshaped = np.broadcast_to(\n",
    "        data.reshape((T, N, 1, Q)),\n",
    "        shape=(T, N, G, Q),\n",
    "    )\n",
    "    masked_data = np.ma.masked_array(reshaped, mask)\n",
    "    result = op_f(masked_data, axis=1, keepdims=False)\n",
    "    return result.data\n",
    "\n",
    "\n",
    "%timeit apply_2(agg_operation, scope, group_granularity, data)\n",
    "res2 = apply_2(agg_operation, scope, group_granularity, data)\n",
    "print(f\"{res2.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: use Pandas, adding a column for group membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 ms ± 7.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "res3.shape=(366, 187, 6)\n"
     ]
    }
   ],
   "source": [
    "def apply_3(agg, scope, grouping, data):\n",
    "    gran = CensusGranularity.of(grouping)\n",
    "    node_ids = scope.node_ids\n",
    "    map_to_group = gran.truncate\n",
    "\n",
    "    groups = np.array([map_to_group(x) for x in node_ids])\n",
    "\n",
    "    T, N, Q = data.shape\n",
    "    df = pd.DataFrame(data=data.reshape((-1, Q)))\n",
    "    df[\"tick\"] = np.repeat(np.arange(T), N)\n",
    "    df[\"geo_group\"] = np.tile(groups, T)\n",
    "    df = (\n",
    "        df.groupby([\"tick\", \"geo_group\"], sort=False)\n",
    "        .agg(func=agg)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df.to_numpy().reshape((T, -1, Q))\n",
    "\n",
    "\n",
    "%timeit apply_3(agg_operation, scope, group_granularity, data)\n",
    "res3 = apply_3(agg_operation, scope, group_granularity, data)\n",
    "print(f\"{res3.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 4: a basic Python loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33 s ± 36.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "res4.shape=(366, 187, 6)\n"
     ]
    }
   ],
   "source": [
    "def apply_4(agg, scope, grouping, data):\n",
    "    from math import inf\n",
    "\n",
    "    match agg:\n",
    "        case \"sum\":\n",
    "            op_f = lambda a, b: a + b  # noqa: E731\n",
    "            agg_zero = 0\n",
    "        case \"min\":\n",
    "            op_f = lambda a, b: min(a, b)  # noqa: E731\n",
    "            agg_zero = inf\n",
    "        case \"max\":\n",
    "            op_f = lambda a, b: max(a, b)  # noqa: E731\n",
    "            agg_zero = -inf\n",
    "        case x:\n",
    "            raise ValueError(x)\n",
    "\n",
    "    node_ids = scope.node_ids\n",
    "\n",
    "    gran = CensusGranularity.of(grouping)\n",
    "    groups = gran.truncate_list(node_ids)\n",
    "    T, N, Q = data.shape\n",
    "    G = len(groups)\n",
    "\n",
    "    result = np.full(shape=(T, G, Q), fill_value=agg_zero, dtype=data.dtype)\n",
    "    for i, n in enumerate(node_ids):\n",
    "        g = groups.index(gran.truncate(n))\n",
    "        for t in range(T):\n",
    "            for q in range(Q):\n",
    "                result[t, g, q] = op_f(result[t, g, q], data[t, i, q])\n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit apply_4(agg_operation, scope, group_granularity, data)\n",
    "res4 = apply_4(agg_operation, scope, group_granularity, data)\n",
    "print(f\"{res4.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 5: hybrid numpy and iterate-over-groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333 ms ± 568 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "res5.shape=(366, 187, 6)\n"
     ]
    }
   ],
   "source": [
    "def apply_5(agg, scope, grouping, data):\n",
    "    match agg:\n",
    "        case \"sum\":\n",
    "            op_f = np.sum\n",
    "        case \"min\":\n",
    "            op_f = np.min\n",
    "        case \"max\":\n",
    "            op_f = np.max\n",
    "        case x:\n",
    "            raise ValueError(x)\n",
    "\n",
    "    node_ids = scope.node_ids\n",
    "\n",
    "    groups = CensusGranularity.of(grouping).truncate_list(node_ids)\n",
    "    T, _, Q = data.shape\n",
    "    G = len(groups)\n",
    "\n",
    "    result = np.empty(shape=(T, G, Q), dtype=data.dtype)\n",
    "    for g, group in enumerate(groups):\n",
    "        in_group = np.char.startswith(node_ids, group)\n",
    "        result[:, g, :] = op_f(data[:, in_group, :], axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit apply_5(agg_operation, scope, group_granularity, data)\n",
    "res5 = apply_5(agg_operation, scope, group_granularity, data)\n",
    "print(f\"{res5.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "# Check that we get the same answer with each approach.\n",
    "all(np.array_equal(a, b) for a, b in pairwise([res1, res2, res3, res4, res5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Numpy's masked operations are horrible if your primary concern is performance. In this case, accomplishing the \"mask\" using selection syntax and iterating over the groups is a better option. Pandas is very close though, and this is quite sensitive to the number of groups in the result. The mechanism of grouping on an added column is very simple, so we might do it this way just to be consistent with time aggregates.\n",
    "\n",
    "Note: I also tested using polars for this as a curiosity. It was actually slower than the Pandas approach, though it's possible I don't know enough about how to optimize it. Either way Polars is either not universally faster or not trivially so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
