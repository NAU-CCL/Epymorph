{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# devlog 2023-08-11\n",
    "\n",
    "_author: Tyler Coles_\n",
    "\n",
    "To wrap up movement optimization, lets do some simple benchmarking to compare the performance of the two engines (BasicEngine and HypercubeEngine) under different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(id=3, args=Args(ipm='pei', mm='pei', geo='pei', days=150), basic_time=0.3412574620006126, hypercube_time=0.4623291640000389),\n",
       " Result(id=0, args=Args(ipm='sirs', mm='no', geo='single_pop', days=150), basic_time=0.03445045700027549, hypercube_time=0.0490778160001355),\n",
       " Result(id=2, args=Args(ipm='sparsemod', mm='centroids', geo='us_states_2015', days=150), basic_time=5.59075156200015, hypercube_time=5.595188520999727),\n",
       " Result(id=4, args=Args(ipm='sirs', mm='centroids', geo='maricopa_cbg_2019', days=30), basic_time=89.11756116599918, hypercube_time=45.72292028499942),\n",
       " Result(id=1, args=Args(ipm='no', mm='centroids', geo='us_states_2015', days=150), basic_time=0.6852275270002792, hypercube_time=0.579345139999532)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "from datetime import date\n",
    "from typing import NamedTuple\n",
    "\n",
    "from epymorph.data import geo_library, ipm_library, mm_library\n",
    "from epymorph.movement.basic import BasicEngine\n",
    "from epymorph.movement.hypercube import HypercubeEngine\n",
    "from epymorph.simulation import Simulation\n",
    "\n",
    "uber_params = {\n",
    "    \"alpha\": [0.1, 0.3, 0.2],\n",
    "    \"beta\": 0.4,\n",
    "    \"gamma\": 0.25,  # 1/4\n",
    "    \"xi\": 0.111,  # 1/90\n",
    "    \"phi\": 40.0,\n",
    "    \"omega\": [0.55, 0.05],\n",
    "    \"delta\": [0.333, 0.5, 0.166, 0.142, 0.125],\n",
    "    \"gamma_sparsemod\": [0.166, 0.333, 0.25],\n",
    "    \"rho\": [0.40, 0.175, 0.015, 0.20, 0.60],\n",
    "    \"theta\": 0.1,\n",
    "    \"move_control\": 0.9,\n",
    "    \"infection_duration\": 4.0,\n",
    "    \"immunity_duration\": 90.0,\n",
    "    \"hospitalization_duration\": 14.0,\n",
    "    \"hospitalization_rate\": 0.1,\n",
    "    \"infection_seed_loc\": 0,\n",
    "    \"infection_seed_size\": 10000,\n",
    "}\n",
    "\n",
    "\n",
    "class Args(NamedTuple):\n",
    "    ipm: str\n",
    "    mm: str\n",
    "    geo: str\n",
    "    days: int\n",
    "\n",
    "\n",
    "# Here are the scenarios we will run: each with Basic and Hypercube.\n",
    "jobs = [\n",
    "    # Just a basic SIRS model on a single population with no movement.\n",
    "    Args(\"sirs\", \"no\", \"single_pop\", 150),\n",
    "    # A null IPM but a moderate-sized geo with movement.\n",
    "    Args(\"no\", \"centroids\", \"us_states_2015\", 150),\n",
    "    # The most basic real experiment: Pei.\n",
    "    Args(\"pei\", \"pei\", \"pei\", 150),\n",
    "    # A complex IPM with a moderate geo.\n",
    "    Args(\"sparsemod\", \"centroids\", \"us_states_2015\", 150),\n",
    "    # A very large geo with a real IPM.\n",
    "    Args(\"sirs\", \"centroids\", \"maricopa_cbg_2019\", 30),\n",
    "]\n",
    "\n",
    "\n",
    "class Result(NamedTuple):\n",
    "    id: int\n",
    "    args: Args\n",
    "    basic_time: float\n",
    "    hypercube_time: float\n",
    "\n",
    "\n",
    "def simulate(id: int, args: Args) -> Result:\n",
    "    ipm, mm, geo, days = args\n",
    "    ps = uber_params.copy()\n",
    "    if ipm == \"sparsemod\":\n",
    "        ps[\"gamma\"] = ps[\"gamma_sparsemod\"]\n",
    "\n",
    "    sim1 = Simulation(\n",
    "        geo=geo_library[geo](),\n",
    "        ipm_builder=ipm_library[ipm](),\n",
    "        mvm_builder=mm_library[mm](),\n",
    "        mvm_engine=BasicEngine,\n",
    "    )\n",
    "    t0 = time.perf_counter()\n",
    "    sim1.run(ps, date(2019, 1, 1), days)\n",
    "    t1 = time.perf_counter()\n",
    "    del sim1  # make sure we're not keeping memory tied down\n",
    "\n",
    "    sim2 = Simulation(\n",
    "        geo=geo_library[geo](),\n",
    "        ipm_builder=ipm_library[ipm](),\n",
    "        mvm_builder=mm_library[mm](),\n",
    "        mvm_engine=HypercubeEngine,\n",
    "    )\n",
    "    t2 = time.perf_counter()\n",
    "    sim2.run(ps, date(2019, 1, 1), days)\n",
    "    t3 = time.perf_counter()\n",
    "    del sim2  # make sure we're not keeping memory tied down\n",
    "\n",
    "    return Result(id, args, t1 - t0, t3 - t2)\n",
    "\n",
    "\n",
    "results = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=2) as exec:\n",
    "    futures = {exec.submit(simulate, id, args): id for id, args in enumerate(jobs)}\n",
    "    done, _ = concurrent.futures.wait(futures)\n",
    "    for f in done:\n",
    "        id = futures[f]\n",
    "        try:\n",
    "            results.append(f.result())\n",
    "        except Exception as e:\n",
    "            print(f\"Worker {id} raised an exception: {repr(e)}\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This took me about 2 minutes to run.) Now we can jam the results in a dataframe and calculate the relative speedup/slowdown factor.\n",
    "\n",
    "$$speedup = \\frac{time_{baseline}}{time_{experimental}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>args</th>\n",
       "      <th>basic</th>\n",
       "      <th>hypercube</th>\n",
       "      <th>speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(sirs, no, single_pop, 150)</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.049078</td>\n",
       "      <td>0.701956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(no, centroids, us_states_2015, 150)</td>\n",
       "      <td>0.685228</td>\n",
       "      <td>0.579345</td>\n",
       "      <td>1.182762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(sparsemod, centroids, us_states_2015, 150)</td>\n",
       "      <td>5.590752</td>\n",
       "      <td>5.595189</td>\n",
       "      <td>0.999207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(pei, pei, pei, 150)</td>\n",
       "      <td>0.341257</td>\n",
       "      <td>0.462329</td>\n",
       "      <td>0.738127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(sirs, centroids, maricopa_cbg_2019, 30)</td>\n",
       "      <td>89.117561</td>\n",
       "      <td>45.722920</td>\n",
       "      <td>1.949079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           args      basic  hypercube  \\\n",
       "id                                                                      \n",
       "0                   (sirs, no, single_pop, 150)   0.034450   0.049078   \n",
       "1          (no, centroids, us_states_2015, 150)   0.685228   0.579345   \n",
       "2   (sparsemod, centroids, us_states_2015, 150)   5.590752   5.595189   \n",
       "3                          (pei, pei, pei, 150)   0.341257   0.462329   \n",
       "4      (sirs, centroids, maricopa_cbg_2019, 30)  89.117561  45.722920   \n",
       "\n",
       "     speedup  \n",
       "id            \n",
       "0   0.701956  \n",
       "1   1.182762  \n",
       "2   0.999207  \n",
       "3   0.738127  \n",
       "4   1.949079  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_records(\n",
    "    results, index=\"id\", columns=[\"id\", \"args\", \"basic\", \"hypercube\"]\n",
    ").sort_index()\n",
    "\n",
    "df[\"speedup\"] = df[\"basic\"] / df[\"hypercube\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly HypercubeEngine is not always an improvement! It does seem to perform better for very large GEOs, but only by a factor of 2. To explain the lack of overall improvement, I believe Hypercube does save time processing movement but requires more time processing the IPM. Interfacing Hypercube's world representation with the IPM layer requires copying to intermediary arrays and this takes time. The IPM is currently naive to the underlying data representation and thus cannot optimize its processing accordingly. Future work could address this by making the \"engine\" concept holistic rather than limited to the movement system.\n",
    "\n",
    "Overall I would call this effort a success. It involved not only introducing the concept of MovementEngine, rewriting the old object-based way of handling movement (as BasicEngine), and adding the HypercubeEngine -- it also involved improvements upon BasicEngine's algorithm. The original baseline `(sirs, centroids, maricopa_cbg_2019, 30)` took around 319 seconds; so we've still achieved a speedup of 3.5 and 7.0 (for Basic and Hypercube respectively) for this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
