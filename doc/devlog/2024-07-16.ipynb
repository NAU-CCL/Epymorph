{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024/07/16 PRISM File Usage and Size\n",
    "_Author: Meaghan Freund_\n",
    "\n",
    "PRISM (Parameter-elevation Regressions on Independent Slopes Model) is an Oregon state website, which supplies daily, monthly, and annual files of observed climate values and attributes as raster files. These files are formatted as zip files, in which contains a lot of information considering that the geography of the raster datasets is all of the United States, excluding Hawaii and Alaska. \n",
    "\n",
    "Considering a daily view of these values, one zip file (which contains 8 files in each instance) would have to be downloaded for a singular day, which could take up loads of space and time. Before making a proper ADRIO template for utilizing the PRISM data, \n",
    "some testing is required to determine the amount of space for a range of days the data takes up and the time it takes to run.\n",
    "\n",
    "For more information concerning PRISM, visit the PRISM website homepage: _https://prism.oregonstate.edu/_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Data\n",
    "\n",
    "The following script is designed to fetch the urls of the zip files that are needed for a specified number of days. The urls of PRISM files have the same file name format, but change based on the attributes and the dates, which the fetch_raster accounts for with the given parameters. These functions do not incorporate the caching system that the ADRIO template for PRISM would have, since the current issue is actively downloading the zip files for PRISM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "from typing import Generator\n",
    "import zipfile\n",
    "from datetime import date as datetype\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from epymorph.data_shape import Shapes\n",
    "from epymorph.error import DataResourceException\n",
    "from epymorph.simulation import AttributeDef, TimeFrame\n",
    "\n",
    "# abbreviations for file urls\n",
    "attrib_vars = {\n",
    "    \"name\": [\"\"],\n",
    "    \"precipitation\": [\"ppt\"],\n",
    "    \"mean_temperature\": [\"tmean\"],\n",
    "    \"min_temperature\": [\"tmin\"],\n",
    "    \"max_temperature\": [\"tmax\"],\n",
    "    \"mean_dew_point_temp\": [\"tdmean\"],\n",
    "    \"min_vpd\": [\"vpdmin\"],\n",
    "    \"max_vpd\": [\"vpdmax\"],\n",
    "}\n",
    "\n",
    "\n",
    "def download_bil_file(url):\n",
    "    \"\"\"Opens the given url of a zip file and outputs the file path of the bil file\"\"\"\n",
    "    # set up directory and zip file\n",
    "    local_zip_file = Path(url).name\n",
    "    extract_dir = local_zip_file.replace(\".zip\", \"\")\n",
    "\n",
    "    # open the url and open the zip\n",
    "    response = requests.get(url, timeout=10)\n",
    "    with Path(local_zip_file).open(\"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(local_zip_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    bil_file_path = None\n",
    "\n",
    "    # search for the bil file inside\n",
    "    for root, dirs, files in os.walk(extract_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".bil\"):\n",
    "                bil_file_path = Path(root) / file\n",
    "                break\n",
    "    return bil_file_path\n",
    "\n",
    "\n",
    "def fetch_raster(attribute: AttributeDef, date_range: TimeFrame):\n",
    "    \"\"\"\n",
    "    Fetches the raster values at the url with the given attribute and date range.\n",
    "    \"\"\"\n",
    "\n",
    "    # set some date variables with the date_range\n",
    "    latest_date = datetype.today() - timedelta(days=1)\n",
    "    first_day = date_range.start_date\n",
    "    last_day = date_range.end_date\n",
    "\n",
    "    # create the list of days in date_range\n",
    "    date_list = [\n",
    "        first_day + timedelta(days=x) for x in range((last_day - first_day).days + 1)\n",
    "    ]\n",
    "\n",
    "    # the stability of PRISM data is defined by date, specified around the 6 month mark\n",
    "    six_months_ago = datetype.today() + relativedelta(months=-6)\n",
    "    last_completed_month = six_months_ago.replace(day=1) - timedelta(days=1)\n",
    "\n",
    "    for single_date in date_list:\n",
    "        if (\n",
    "            single_date.year == latest_date.year\n",
    "            and single_date.month == latest_date.month\n",
    "        ):\n",
    "            stability = \"early\"\n",
    "\n",
    "        # if it is before the last finished month\n",
    "        elif single_date >= last_completed_month:\n",
    "            stability = \"provisional\"\n",
    "\n",
    "        # if it is older than 6 completed months\n",
    "        else:\n",
    "            stability = \"stable\"\n",
    "\n",
    "        # format the date for the url\n",
    "        formatted_date = single_date.strftime(\"%Y%m%d\")\n",
    "        year = single_date.year\n",
    "\n",
    "        # get the abbreviation for the variable\n",
    "        for var in attrib_vars.keys():\n",
    "            if str(attribute.name).startswith(var):\n",
    "                attribute_name = attrib_vars[var][0]\n",
    "\n",
    "        url = f\"https://ftp.prism.oregonstate.edu/daily/{attribute_name}/{year}/PRISM_{attribute_name}_{stability}_4kmD2_{formatted_date}_bil.zip\"\n",
    "\n",
    "        bil_file_paths = download_bil_file(url)\n",
    "\n",
    "        yield bil_file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched files from PRISM: \n",
      "PRISM_ppt_stable_4kmD2_20230301_bil/PRISM_ppt_stable_4kmD2_20230301_bil.bil\n",
      "\n",
      "PRISM_ppt_stable_4kmD2_20230302_bil/PRISM_ppt_stable_4kmD2_20230302_bil.bil\n",
      "\n",
      "PRISM_ppt_stable_4kmD2_20230303_bil/PRISM_ppt_stable_4kmD2_20230303_bil.bil\n",
      "\n",
      "PRISM_ppt_stable_4kmD2_20230304_bil/PRISM_ppt_stable_4kmD2_20230304_bil.bil\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set example attributes\n",
    "start_date = datetype(2023, 3, 1)\n",
    "days = 3\n",
    "end_date = start_date + timedelta(days=days)\n",
    "date_range = TimeFrame.range(start_date, end_date)\n",
    "attribute = AttributeDef(\"precipitation\", float, Shapes.NxN)\n",
    "\n",
    "files = fetch_raster(attribute, date_range)\n",
    "print(\"Fetched files from PRISM: \")\n",
    "for file in files:\n",
    "    print(f\"{file}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the Data via Centroids\n",
    "\n",
    "For reading raster files, it is uncertain on how the data for granularities would be read. Ideally for an ADRIO template for PRISM, we would start with multiple strategies and narrow down the most accurate representation of locations. However for simplicity in testing, I have implemented the manner of fetching the coordinates of centroids of a given location. This given example is using the county granularity and calculating the centroid from there.\n",
    "\n",
    "The output of these functions are matrices, read with the columns being the dates, the enclosed rows being each county, and the intersection being the value for that county on that day. This example shows the amount of precipitation (in mm) in two Ohio counties in July 1st-4th, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date as datetype\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from epymorph.data_shape import Shapes\n",
    "from epymorph.simulation import AttributeDef, TimeFrame\n",
    "\n",
    "\n",
    "def raster_values_at_centroids(\n",
    "    attribute: AttributeDef, date_range: TimeFrame, centroids: NDArray\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Retrieves the raster value at a centroid of a geoid.\n",
    "    \"\"\"\n",
    "    raster_paths = fetch_raster(attribute, date_range)\n",
    "    results = []\n",
    "\n",
    "    # read in each file\n",
    "    for raster_file in raster_paths:\n",
    "        raster_path = Path(raster_file)\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            # retrieve the coordinates from centroids\n",
    "            coords = [\n",
    "                (x, y) for x, y in zip(centroids[\"longitude\"], centroids[\"latitude\"])\n",
    "            ]\n",
    "            # round and save the raster values\n",
    "            values = [round(x[0], 3) for x in src.sample(coords)]\n",
    "\n",
    "        results.append(values)\n",
    "\n",
    "    # create numpy array\n",
    "    climate_vals = np.array(results)\n",
    "\n",
    "    return climate_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster values at county centroids ['39001', '39083']:\n",
      "\n",
      "On dates: 03/01/2023 - 03/04/2023\n",
      "[[ 0.     0.   ]\n",
      " [ 3.676  0.   ]\n",
      " [ 3.05   0.   ]\n",
      " [19.941 37.54 ]]\n"
     ]
    }
   ],
   "source": [
    "from epymorph.data_type import CentroidDType\n",
    "\n",
    "counties = [\"39001\", \"39083\"]  # Adams County and Knox County\n",
    "centroids = np.array(\n",
    "    [(-83.47214942, 38.84550293), (-82.42153605, 40.39876741)], dtype=CentroidDType\n",
    ")\n",
    "\n",
    "# set example attributes\n",
    "start_date = datetype(2023, 3, 1)\n",
    "end_date = datetype(2023, 3, 4)\n",
    "date_range = TimeFrame.range(start_date, end_date)\n",
    "start_date_str = start_date.strftime(\"%m/%d/%Y\")\n",
    "end_date_str = end_date.strftime(\"%m/%d/%Y\")\n",
    "attribute = AttributeDef(\"precipitation\", float, Shapes.NxN)\n",
    "\n",
    "# call function and print\n",
    "raster_values_array = raster_values_at_centroids(attribute, date_range, centroids)\n",
    "\n",
    "print(f\"Raster values at county centroids {counties}:\\n\")\n",
    "print(f\"On dates: {start_date_str} - {end_date_str}\")\n",
    "print(raster_values_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Data Experimentation\n",
    "\n",
    "The above were basic examples, but what about for multiple locations and multiple days? Each date and attribute is a singular zip file, which means there would be 30 zip files (240 files total) downloaded if a user wanted the scope of a month. Below will test for a single month in 2024, in all counties in the state of Arizona, with two climate variables: precipitation and maximum temperature, which are measured in millimeters and degrees Celsius respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### June 2024 Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetype(2024, 6, 1)\n",
    "end_date = datetype(2024, 6, 30)\n",
    "TimeFrame.duration_days = 30\n",
    "date_range = TimeFrame.range(start_date, end_date)\n",
    "\n",
    "# list of all of the counties in Arizona\n",
    "all_counties_az = [\n",
    "    \"04001\",\n",
    "    \"04003\",\n",
    "    \"04005\",\n",
    "    \"04007\",\n",
    "    \"04009\",\n",
    "    \"04011\",\n",
    "    \"04012\",\n",
    "    \"04013\",\n",
    "    \"04015\",\n",
    "    \"04017\",\n",
    "    \"04019\",\n",
    "    \"04021\",\n",
    "    \"04023\",\n",
    "    \"04025\",\n",
    "    \"04027\",\n",
    "]\n",
    "\n",
    "# manual centroids for all counties in Arizona\n",
    "centroids = np.array(\n",
    "    [\n",
    "        (-109.48884962, 35.3955288),\n",
    "        (-109.75126314, 31.87963709),\n",
    "        (-111.77052096, 35.83872483),\n",
    "        (-110.81163686, 33.79970237),\n",
    "        (-109.88745163, 32.9326627),\n",
    "        (-109.24035541, 33.21540167),\n",
    "        (-113.98157752, 33.72938684),\n",
    "        (-112.49151144, 33.34903944),\n",
    "        (-113.75790301, 35.70406832),\n",
    "        (-110.32141935, 35.39955034),\n",
    "        (-111.7898635, 32.09739903),\n",
    "        (-111.3447399, 32.90436651),\n",
    "        (-110.84651691, 31.52596126),\n",
    "        (-112.55373567, 34.59984444),\n",
    "        (-113.9056188, 32.76961884),\n",
    "    ],\n",
    "    dtype=CentroidDType,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Centroid Raster Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster values in all counties in Arizona:\n",
      "[[0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.6700e+00 0.0000e+00 0.0000e+00 3.2110e+00 4.8600e-01 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 2.3840e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0200e+00 1.0016e+01 0.0000e+00 0.0000e+00 6.7400e-01 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0400e+00\n",
      "  4.3030e+00 0.0000e+00 0.0000e+00]\n",
      " [2.7360e+00 4.7300e-01 1.8840e+00 5.9500e-01 2.3960e+00 1.9540e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 3.3140e+00 0.0000e+00\n",
      "  6.1330e+00 3.2990e+00 0.0000e+00]\n",
      " [0.0000e+00 3.0020e+00 3.9630e+00 3.4000e-01 6.1930e+00 5.3400e-01\n",
      "  0.0000e+00 0.0000e+00 1.4560e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  1.0287e+01 8.8800e-01 0.0000e+00]\n",
      " [0.0000e+00 3.0020e+00 2.5650e+00 3.8890e+00 0.0000e+00 2.1200e+00\n",
      "  0.0000e+00 1.6840e+00 0.0000e+00 0.0000e+00 1.2822e+01 5.1720e+00\n",
      "  2.8620e+00 1.9730e+00 0.0000e+00]\n",
      " [0.0000e+00 6.0000e-03 1.0247e+01 1.3700e-01 2.3600e-01 0.0000e+00\n",
      "  0.0000e+00 9.8500e-01 3.3600e+00 0.0000e+00 6.0000e-03 0.0000e+00\n",
      "  0.0000e+00 1.0479e+01 0.0000e+00]\n",
      " [7.5600e-01 0.0000e+00 5.5100e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 2.3440e+00 0.0000e+00 0.0000e+00\n",
      "  1.7640e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0254e+01 7.7500e-01 6.2100e-01 0.0000e+00 0.0000e+00 1.8490e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 6.5870e+00 0.0000e+00 0.0000e+00\n",
      "  6.2430e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 6.3200e-01 0.0000e+00 0.0000e+00 4.3400e-01 5.3100e-01\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.1470e+01 2.4510e+00\n",
      "  1.3955e+01 0.0000e+00 0.0000e+00]\n",
      " [3.0800e-01 6.3160e+00 0.0000e+00 6.5200e-01 6.0000e-03 1.3000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 7.1600e-01 7.5250e+00 0.0000e+00\n",
      "  3.7170e+00 0.0000e+00 0.0000e+00]]\n",
      "\n",
      "Dates: 06/01/2024 - 06/30/2024\n",
      "\n",
      "Counties: ['04001', '04003', '04005', '04007', '04009', '04011', '04012', '04013', '04015', '04017', '04019', '04021', '04023', '04025', '04027']\n"
     ]
    }
   ],
   "source": [
    "attribute = AttributeDef(\"precipitation\", float, Shapes.NxN)\n",
    "\n",
    "raster_values_array = raster_values_at_centroids(attribute, date_range, centroids)\n",
    "\n",
    "print(\"Raster values in all counties in Arizona:\")\n",
    "print(raster_values_array)\n",
    "\n",
    "start_date_str = start_date.strftime(\"%m/%d/%Y\")\n",
    "end_date_str = end_date.strftime(\"%m/%d/%Y\")\n",
    "print(f\"\\nDates: {start_date_str} - {end_date_str}\")\n",
    "print(f\"\\nCounties: {all_counties_az}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "Arizona in general does not accumulate as much rain as other states in the east, so an output of low numbers for Arizona is to be expected. However, the opposite is anticipated for the maximum temperature, since Arizona is much warmer, especially in the summer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### June 2024 Maximum Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = AttributeDef(\"max_temperature\", float, Shapes.NxN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Centroid Raster Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster values in all counties in Arizona:\n",
      "[[30.91  34.824 29.277 35.232 38.297 34.279 39.348 41.325 32.038 31.85\n",
      "  36.453 39.442 33.715 29.565 40.552]\n",
      " [30.831 35.332 27.968 34.898 38.879 34.565 37.88  40.474 30.567 31.475\n",
      "  35.698 39.413 33.805 27.695 40.076]\n",
      " [28.962 33.967 26.486 32.932 37.443 33.11  37.068 40.116 29.426 29.749\n",
      "  34.616 38.414 32.756 25.776 39.643]\n",
      " [29.672 34.225 28.041 33.306 37.116 33.171 38.108 39.83  30.941 30.931\n",
      "  33.794 37.851 32.187 28.039 38.997]\n",
      " [30.904 34.092 28.898 34.33  37.233 33.724 39.108 40.153 32.601 32.45\n",
      "  34.823 37.602 33.368 30.639 38.976]\n",
      " [33.315 37.17  31.948 37.743 41.368 37.804 41.561 42.792 35.429 34.755\n",
      "  38.854 40.482 36.367 32.966 40.459]\n",
      " [35.638 38.75  34.278 39.627 42.574 39.207 43.205 44.314 37.06  37.119\n",
      "  40.148 42.176 37.33  34.512 42.119]\n",
      " [34.656 37.456 32.766 38.452 41.649 37.555 41.424 43.775 34.914 35.905\n",
      "  39.652 43.038 36.606 31.507 42.64 ]\n",
      " [33.067 36.31  30.262 36.392 38.762 36.026 40.213 42.917 33.658 33.648\n",
      "  36.463 41.337 34.814 29.768 42.342]\n",
      " [28.39  33.134 27.612 34.163 35.5   31.001 39.459 41.983 31.614 29.383\n",
      "  36.532 39.876 32.762 28.256 39.041]\n",
      " [27.269 34.91  29.669 36.134 38.703 34.4   39.99  41.335 32.642 30.843\n",
      "  36.665 39.599 34.504 30.639 40.831]\n",
      " [33.504 38.018 32.399 38.753 41.486 37.416 42.564 44.231 35.466 34.967\n",
      "  40.068 42.781 37.574 33.693 42.273]\n",
      " [35.645 39.818 32.908 39.052 43.122 39.436 41.636 44.229 35.936 36.773\n",
      "  39.874 42.655 38.9   32.688 42.541]\n",
      " [34.327 39.104 28.764 35.888 42.731 39.135 40.856 43.023 31.832 33.83\n",
      "  37.491 39.829 35.722 30.045 42.181]\n",
      " [31.065 37.436 29.481 36.219 40.52  36.515 42.625 42.331 34.77  32.611\n",
      "  35.605 39.649 35.17  32.283 42.871]\n",
      " [33.004 37.015 31.928 38.125 41.123 37.476 43.241 45.067 34.961 34.875\n",
      "  38.553 42.53  36.901 32.223 44.242]\n",
      " [33.221 37.869 29.94  37.354 40.607 36.927 40.854 44.126 32.341 34.229\n",
      "  38.561 42.727 36.746 30.016 42.519]\n",
      " [31.486 36.571 27.889 35.176 40.414 35.792 38.89  40.608 30.286 32.314\n",
      "  35.021 40.08  34.514 27.949 40.222]\n",
      " [30.702 35.625 27.276 34.39  38.443 34.18  38.195 40.24  28.265 31.706\n",
      "  34.232 39.258 33.206 27.666 39.283]\n",
      " [32.181 37.294 28.222 35.703 40.493 36.508 38.552 40.721 30.531 32.636\n",
      "  35.726 39.946 35.498 29.606 40.713]\n",
      " [32.712 37.324 31.109 37.54  38.748 34.77  41.698 44.896 33.727 34.269\n",
      "  40.827 43.575 39.144 32.044 42.582]\n",
      " [32.392 34.842 31.429 36.441 36.946 32.626 43.327 46.561 34.8   34.446\n",
      "  39.441 42.976 35.633 32.986 45.435]\n",
      " [28.84  31.497 30.591 34.18  31.742 28.219 42.359 42.264 34.64  31.74\n",
      "  36.05  37.919 30.612 31.88  42.861]\n",
      " [30.467 35.797 30.108 34.643 38.205 34.394 42.373 43.723 35.924 32.383\n",
      "  35.627 39.476 33.652 31.342 43.186]\n",
      " [32.834 35.654 29.619 37.768 39.412 35.633 43.344 44.305 36.122 33.671\n",
      "  38.092 41.394 35.146 31.336 44.654]\n",
      " [34.27  36.542 30.894 36.622 40.031 36.958 42.769 43.112 35.545 34.377\n",
      "  35.82  39.576 34.428 30.719 43.497]\n",
      " [33.163 36.584 29.608 36.976 39.909 36.678 42.515 44.129 34.86  33.228\n",
      "  36.454 40.904 34.298 31.427 43.17 ]\n",
      " [29.137 36.294 29.836 36.796 40.304 35.325 43.166 44.188 34.857 31.858\n",
      "  37.468 41.635 35.322 31.655 43.384]\n",
      " [32.42  35.194 29.711 36.846 39.572 35.59  41.862 44.09  33.916 33.799\n",
      "  37.384 41.685 33.964 29.61  42.625]\n",
      " [29.024 34.463 30.965 36.406 37.552 34.846 42.471 44.543 34.741 30.66\n",
      "  37.059 40.358 33.476 31.673 44.194]]\n",
      "\n",
      "Dates: 06/01/2024 - 06/30/2024\n",
      "\n",
      "Counties: ['04001', '04003', '04005', '04007', '04009', '04011', '04012', '04013', '04015', '04017', '04019', '04021', '04023', '04025', '04027']\n"
     ]
    }
   ],
   "source": [
    "raster_values_array = raster_values_at_centroids(attribute, date_range, centroids)\n",
    "\n",
    "print(\"Raster values in all counties in Arizona:\")\n",
    "print(raster_values_array)\n",
    "print(f\"\\nDates: {start_date_str} - {end_date_str}\")\n",
    "print(f\"\\nCounties: {all_counties_az}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Taken Up from PRISM Files\n",
    "\n",
    "The majority of the time spent running comes from fetching the files themselves rather than actually interpreting the raster data. However, the space has yet to be recorded. The following code takes in a basic file path and collects the amount of space all of the dates for those files takes up all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date as datetype\n",
    "from datetime import timedelta\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def generate_file_paths(\n",
    "    template: str, start_date: datetype, num_days: int\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate the file names\"\"\"\n",
    "    file_paths = []\n",
    "    # iterate through everyday\n",
    "    for i in range(num_days):\n",
    "        current_date = start_date + timedelta(days=i)\n",
    "        # format each date\n",
    "        formatted_date = current_date.strftime(\"%Y%m%d\")\n",
    "        file_path = template.replace(\"DATE\", formatted_date)\n",
    "        file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def format_size(size_in_bytes: int) -> str:\n",
    "    \"\"\"Format the file size as a string\"\"\"\n",
    "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n",
    "        # format based on the amount\n",
    "        if size_in_bytes < 1024:\n",
    "            return f\"{size_in_bytes:.2f} {unit}\"\n",
    "        size_in_bytes /= 1024\n",
    "\n",
    "\n",
    "def print_file_size(file_paths: List[str]):\n",
    "    \"\"\"Print the sum of all of the files sizes\"\"\"\n",
    "    file_sum = 0\n",
    "    # add up all of the file sizes\n",
    "    for f in file_paths:\n",
    "        file_path = Path(f)\n",
    "        file_size_bytes = file_path.stat().st_size\n",
    "        file_sum += file_size_bytes\n",
    "\n",
    "    formatted_size = format_size(file_sum)\n",
    "    print(f\"PRISM file size: {formatted_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISM file size: 34.26 MB\n"
     ]
    }
   ],
   "source": [
    "template = \"PRISM_ppt_provisional_4kmD2_DATE_bil.zip\"\n",
    "file_paths = generate_file_paths(template, start_date, TimeFrame.duration_days)\n",
    "\n",
    "print_file_size(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Temperature Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISM file size: 62.34 MB\n"
     ]
    }
   ],
   "source": [
    "template = \"PRISM_tmax_provisional_4kmD2_DATE_bil.zip\"\n",
    "file_paths = generate_file_paths(template, start_date, TimeFrame.duration_days)\n",
    "\n",
    "print_file_size(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size Analysis\n",
    "\n",
    "As shown by the file sizes for the precipitation against the maximum temperature files, the difference is quite large. The maximum temperature files take over 20 more MB of storage than the precipitation files. The likely reason is that maximum temperature has raster values for every single point on the raster grid, as each location has a maximum temperature of some value. Compare this with precipitation in which some locations do not receive any precipitation, leaving areas with 0s. The amount of space taken when fetching and downloading files is pretty significant for the range of a month. As for time, through this experimentation, it has been discovered that weak internet can drastically change the runtime for fetching the zip files from the PRISM website. In addition, having a large amount of files cached or having low storage space can also increase the time for downloading the files. In general, when running the ADRIO template for PRISM, ensure that the given machine has the storage to hold this amount of data and that the provided internet is decently strong."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
