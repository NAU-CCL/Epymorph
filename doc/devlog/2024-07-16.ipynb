{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024/07/16 PRISM File Usage and Size\n",
    "_Author: Meaghan Freund_\n",
    "\n",
    "PRISM (Parameter-elevation Regressions on Independent Slopes Model) is an Oregon state website, which supplies daily, monthly, and annual files of observed climate values and attributes as raster files. These files are formatted as zip files, in which contains a lot of information considering that the geography of the raster datasets is all of the United States, excluding Hawaii and Alaska. \n",
    "\n",
    "Considering a daily view of these values, one zip file (which contains 8 files in each instance) would have to be downloaded for a singular day, which could take up loads of space and time. Before making a proper ADRIO template for utilizing the PRISM data, \n",
    "some testing is required to determine the amount of space for a range of days the data takes up and the time it takes to run.\n",
    "\n",
    "For more information concerning PRISM, visit the PRISM website homepage: _https://prism.oregonstate.edu/_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Data\n",
    "\n",
    "The following script is designed to fetch the urls of the zip files that are needed for a specified number of days. The urls of PRISM files have the same file name format, but change based on the attributes and the dates, which the fetch_raster accounts for with the given parameters. These functions do not incorporate the caching system that the ADRIO template for PRISM would have, since the current issue is actively downloading the zip files for PRISM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import date as datetype\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from epymorph.data_shape import Shapes\n",
    "from epymorph.error import DataResourceException\n",
    "from epymorph.simulation import AttributeDef, TimeFrame\n",
    "\n",
    "# abbreviations for file urls\n",
    "attrib_vars = {\n",
    "    \"name\": [\"\"],\n",
    "    \"precipitation\": [\"ppt\"],\n",
    "    \"mean_temperature\": [\"tmean\"],\n",
    "    \"min_temperature\": [\"tmin\"],\n",
    "    \"max_temperature\": [\"tmax\"],\n",
    "    \"mean_dew_point_temp\": [\"tdmean\"],\n",
    "    \"min_vpd\": [\"vpdmin\"],\n",
    "    \"max_vpd\": [\"vpdmax\"],\n",
    "}\n",
    "\n",
    "\n",
    "def download_bil_file(url):\n",
    "    \"\"\"Opens the given url of a zip file and outputs the file path of the bil file\"\"\"\n",
    "    # set up directory and zip file\n",
    "    local_zip_file = Path(url).name\n",
    "    extract_dir = local_zip_file.replace(\".zip\", \"\")\n",
    "\n",
    "    # open the url and open the zip\n",
    "    response = requests.get(url, timeout=10)\n",
    "    with Path(local_zip_file).open(\"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(local_zip_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    bil_file_path = None\n",
    "\n",
    "    # search for the bil file inside\n",
    "    for root, dirs, files in os.walk(extract_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".bil\"):\n",
    "                bil_file_path = Path(root) / file\n",
    "                break\n",
    "    return bil_file_path\n",
    "\n",
    "\n",
    "def fetch_raster(attribute: AttributeDef, date_range: TimeFrame):\n",
    "    \"\"\"Fetch the raster files from the PRISM index\"\"\"\n",
    "    # set some date variables with the date_range\n",
    "    latest_date = datetype.today() - timedelta(days=1)\n",
    "    first_day = date_range.start_date\n",
    "    last_day = date_range.end_date\n",
    "\n",
    "    # PRISM only accounts for after 1981 up to the previous day to \"yesterday\"\n",
    "    if first_day.year < 1981 or last_day > latest_date:\n",
    "        msg = (\n",
    "            \"Given date range is out of range, please enter dates between \"\n",
    "            f\"January 1st 1981 and {latest_date}\"\n",
    "        )\n",
    "        raise DataResourceException(msg)\n",
    "\n",
    "    # create the list of days in date_range\n",
    "    date_list = [\n",
    "        first_day + timedelta(days=x) for x in range((last_day - first_day).days + 1)\n",
    "    ]\n",
    "    url_list = []\n",
    "    bil_file_paths = []\n",
    "\n",
    "    # the stability of PRISM data is defined by date, specified around the 6 month mark\n",
    "    six_months_ago = datetype.today() + relativedelta(months=-6)\n",
    "    last_completed_month = six_months_ago.replace(day=1) - timedelta(days=1)\n",
    "\n",
    "    for single_date in date_list:\n",
    "        # if it is within the current month\n",
    "        if (\n",
    "            single_date.year == latest_date.year\n",
    "            and single_date.month == latest_date.month\n",
    "        ):\n",
    "            stability = \"early\"\n",
    "\n",
    "        # if it is before the last finished month\n",
    "        elif single_date >= last_completed_month:\n",
    "            stability = \"provisional\"\n",
    "\n",
    "        # if it is older than 6 completed months\n",
    "        else:\n",
    "            stability = \"stable\"\n",
    "\n",
    "        # format the date for the urls\n",
    "        formatted_date = single_date.strftime(\"%Y%m%d\")\n",
    "        year = single_date.year\n",
    "\n",
    "        # get the abbreviation for the variable\n",
    "        for var in attrib_vars.keys():\n",
    "            if str(attribute.name).startswith(var):\n",
    "                attribute_name = attrib_vars[var][0]\n",
    "\n",
    "        url = f\"https://ftp.prism.oregonstate.edu/daily/{attribute_name}/{year}/PRISM_{attribute_name}_{stability}_4kmD2_{formatted_date}_bil.zip\"\n",
    "        url_list.append(url)\n",
    "\n",
    "    # output all of the urls of the bil files\n",
    "    bil_file_paths = [download_bil_file(url) for url in url_list]\n",
    "\n",
    "    return bil_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched files from PRISM: \n",
      "PRISM_ppt_stable_4kmD2_20230301_bil/PRISM_ppt_stable_4kmD2_20230301_bil.bil\n",
      "\n",
      "PRISM_ppt_stable_4kmD2_20230302_bil/PRISM_ppt_stable_4kmD2_20230302_bil.bil\n",
      "\n",
      "PRISM_ppt_stable_4kmD2_20230303_bil/PRISM_ppt_stable_4kmD2_20230303_bil.bil\n",
      "\n",
      "PRISM_ppt_stable_4kmD2_20230304_bil/PRISM_ppt_stable_4kmD2_20230304_bil.bil\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set example attributes\n",
    "start_date = datetype(2023, 3, 1)\n",
    "days = 3\n",
    "end_date = start_date + timedelta(days=days)\n",
    "date_range = TimeFrame.range(start_date, end_date)\n",
    "attribute = AttributeDef(\"precipitation\", float, Shapes.NxN)\n",
    "\n",
    "files = fetch_raster(attribute, date_range)\n",
    "print(\"Fetched files from PRISM: \")\n",
    "for file in files:\n",
    "    print(f\"{file}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the Data via Centroids\n",
    "\n",
    "For reading raster files, it is uncertain on how the data for granularities would be read. Ideally for an ADRIO template for PRISM, we would start with multiple strategies and narrow down the most accurate representation of locations. However for simplicity in testing, I have implemented the manner of fetching the coordinates of centroids of a given location. This given example is using the county granularity and calculating the centroid from there.\n",
    "\n",
    "The output of these functions are matrices, read with the columns being the dates, the enclosed rows being each county, and the intersection being the value for that county on that day. This example shows the amount of precipitation (in mm) in two Ohio counties in July 1st-4th, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date as datetype\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from epymorph.data_shape import Shapes\n",
    "from epymorph.simulation import AttributeDef, TimeFrame\n",
    "\n",
    "\n",
    "def raster_values_at_centroids(\n",
    "    attribute: AttributeDef, date_range: TimeFrame, centroids: NDArray\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Retrieves the raster value at a centroid of a geoid.\n",
    "    \"\"\"\n",
    "    raster_paths = fetch_raster(attribute, date_range)\n",
    "    results = []\n",
    "\n",
    "    # read in each file\n",
    "    for raster_file in raster_paths:\n",
    "        raster_path = Path(raster_file)\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            # retrieve the coordinates from centroids\n",
    "            coords = [\n",
    "                (x, y) for x, y in zip(centroids[\"longitude\"], centroids[\"latitude\"])\n",
    "            ]\n",
    "            # round and save the raster values\n",
    "            values = [round(x[0], 3) for x in src.sample(coords)]\n",
    "\n",
    "        results.append(values)\n",
    "\n",
    "    # create numpy array\n",
    "    climate_vals = np.array(results)\n",
    "\n",
    "    return climate_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster values at county centroids ['39001', '39083']:\n",
      "\n",
      "On dates: 03/01/2023 - 03/04/2023\n",
      "[[ 0.     0.   ]\n",
      " [ 3.676  0.   ]\n",
      " [ 3.05   0.   ]\n",
      " [19.941 37.54 ]]\n"
     ]
    }
   ],
   "source": [
    "from epymorph.data_type import CentroidDType\n",
    "\n",
    "counties = [\"39001\", \"39083\"]  # Adams County and Knox County\n",
    "centroids = np.array(\n",
    "    [(-83.47214942, 38.84550293), (-82.42153605, 40.39876741)], dtype=CentroidDType\n",
    ")\n",
    "\n",
    "# set example attributes\n",
    "start_date = datetype(2023, 3, 1)\n",
    "end_date = datetype(2023, 3, 4)\n",
    "date_range = TimeFrame.range(start_date, end_date)\n",
    "start_date_str = start_date.strftime(\"%m/%d/%Y\")\n",
    "end_date_str = end_date.strftime(\"%m/%d/%Y\")\n",
    "attribute = AttributeDef(\"precipitation\", float, Shapes.NxN)\n",
    "\n",
    "# call function and print\n",
    "raster_values_array = raster_values_at_centroids(attribute, date_range, centroids)\n",
    "\n",
    "print(f\"Raster values at county centroids {counties}:\\n\")\n",
    "print(f\"On dates: {start_date_str} - {end_date_str}\")\n",
    "print(raster_values_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Data Experimentation\n",
    "\n",
    "The above were basic examples, but what about for multiple locations and multiple days? Each date and attribute is a singular zip file, which means there would be 30 zip files (240 files total) downloaded if a user wanted the scope of a month. Below will test for a single month in 2024, in all counties in the state of Arizona, with two climate variables: precipitation and maximum temperature, which are measured in millimeters and degrees Celsius respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### June 2024 Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetype(2024, 6, 1)\n",
    "end_date = datetype(2024, 6, 30)\n",
    "TimeFrame.duration_days = 30\n",
    "date_range = TimeFrame.range(start_date, end_date)\n",
    "\n",
    "# list of all of the counties in Arizona\n",
    "all_counties_az = [\n",
    "    \"04001\",\n",
    "    \"04003\",\n",
    "    \"04005\",\n",
    "    \"04007\",\n",
    "    \"04009\",\n",
    "    \"04011\",\n",
    "    \"04012\",\n",
    "    \"04013\",\n",
    "    \"04015\",\n",
    "    \"04017\",\n",
    "    \"04019\",\n",
    "    \"04021\",\n",
    "    \"04023\",\n",
    "    \"04025\",\n",
    "    \"04027\",\n",
    "]\n",
    "\n",
    "# manual centroids for all counties in Arizona\n",
    "centroids = np.array(\n",
    "    [\n",
    "        (-109.48884962, 35.3955288),\n",
    "        (-109.75126314, 31.87963709),\n",
    "        (-111.77052096, 35.83872483),\n",
    "        (-110.81163686, 33.79970237),\n",
    "        (-109.88745163, 32.9326627),\n",
    "        (-109.24035541, 33.21540167),\n",
    "        (-113.98157752, 33.72938684),\n",
    "        (-112.49151144, 33.34903944),\n",
    "        (-113.75790301, 35.70406832),\n",
    "        (-110.32141935, 35.39955034),\n",
    "        (-111.7898635, 32.09739903),\n",
    "        (-111.3447399, 32.90436651),\n",
    "        (-110.84651691, 31.52596126),\n",
    "        (-112.55373567, 34.59984444),\n",
    "        (-113.9056188, 32.76961884),\n",
    "    ],\n",
    "    dtype=CentroidDType,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Centroid Raster Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster values in all counties in Arizona:\n",
      "[[0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [6.0000e-02 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.7720e+00 0.0000e+00 0.0000e+00 2.9750e+00 5.3800e-01 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 2.3260e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0780e+00 1.0279e+01 0.0000e+00 0.0000e+00 7.4300e-01 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0120e+00\n",
      "  3.6700e+00 0.0000e+00 0.0000e+00]\n",
      " [2.8350e+00 4.8400e-01 1.9970e+00 5.4200e-01 2.5450e+00 2.7680e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 2.3360e+00 0.0000e+00\n",
      "  5.2520e+00 3.1450e+00 0.0000e+00]\n",
      " [0.0000e+00 3.0810e+00 4.2030e+00 3.5300e-01 6.5730e+00 7.6600e-01\n",
      "  0.0000e+00 0.0000e+00 1.6080e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  8.8040e+00 8.4200e-01 0.0000e+00]\n",
      " [0.0000e+00 3.0820e+00 2.6980e+00 3.3640e+00 0.0000e+00 3.3640e+00\n",
      "  0.0000e+00 1.7170e+00 0.0000e+00 0.0000e+00 9.0090e+00 5.0280e+00\n",
      "  2.4490e+00 1.8740e+00 0.0000e+00]\n",
      " [0.0000e+00 3.0000e-03 1.0871e+01 2.4700e-01 2.4400e-01 0.0000e+00\n",
      "  0.0000e+00 1.0030e+00 3.7770e+00 0.0000e+00 5.0000e-03 0.0000e+00\n",
      "  0.0000e+00 9.9930e+00 0.0000e+00]\n",
      " [7.8000e-01 0.0000e+00 5.8420e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 2.4140e+00 0.0000e+00 0.0000e+00\n",
      "  1.5110e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0593e+01 7.9400e-01 6.5800e-01 0.0000e+00 0.0000e+00 2.6110e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 6.7790e+00 0.0000e+00 0.0000e+00\n",
      "  5.3400e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 6.4800e-01 0.0000e+00 0.0000e+00 4.5600e-01 7.7800e-01\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 7.8910e+00 2.5330e+00\n",
      "  1.1945e+01 0.0000e+00 0.0000e+00]\n",
      " [3.0600e-01 6.4800e+00 0.0000e+00 4.4200e-01 5.0000e-03 1.8640e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 7.1700e-01 5.1910e+00 0.0000e+00\n",
      "  3.1790e+00 0.0000e+00 0.0000e+00]]\n",
      "\n",
      "Dates: 06/01/2024 - 06/30/2024\n",
      "\n",
      "Counties: ['04001', '04003', '04005', '04007', '04009', '04011', '04012', '04013', '04015', '04017', '04019', '04021', '04023', '04025', '04027']\n"
     ]
    }
   ],
   "source": [
    "attribute = AttributeDef(\"precipitation\", float, Shapes.NxN)\n",
    "\n",
    "raster_values_array = raster_values_at_centroids(attribute, date_range, centroids)\n",
    "\n",
    "print(\"Raster values in all counties in Arizona:\")\n",
    "print(raster_values_array)\n",
    "\n",
    "start_date_str = start_date.strftime(\"%m/%d/%Y\")\n",
    "end_date_str = end_date.strftime(\"%m/%d/%Y\")\n",
    "print(f\"\\nDates: {start_date_str} - {end_date_str}\")\n",
    "print(f\"\\nCounties: {all_counties_az}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "Arizona in general does not accumulate as much rain as other states in the east, so an output of low numbers for Arizona is to be expected. However, the opposite is anticipated for the maximum temperature, since Arizona is much warmer, especially in the summer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### June 2024 Maximum Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = AttributeDef(\"max_temperature\", float, Shapes.NxN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Centroid Raster Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster values in all counties in Arizona:\n",
      "[[30.884 34.701 29.102 35.193 38.369 33.943 39.124 41.115 32.026 31.787\n",
      "  36.58  39.248 34.635 28.623 40.465]\n",
      " [30.815 35.276 28.102 34.82  38.712 34.123 37.832 40.148 30.554 31.478\n",
      "  36.292 39.252 35.138 27.446 39.924]\n",
      " [28.947 33.646 26.424 32.92  37.43  32.722 36.984 39.84  29.408 29.771\n",
      "  35.303 38.266 33.723 26.545 39.45 ]\n",
      " [29.668 33.986 27.909 33.302 37.011 32.932 37.959 39.606 30.93  30.894\n",
      "  34.831 37.689 33.046 27.478 38.922]\n",
      " [30.909 34.1   28.998 34.19  37.187 33.32  38.878 39.598 32.549 32.366\n",
      "  35.653 37.534 34.108 29.691 38.939]\n",
      " [33.342 36.918 32.011 37.588 41.239 37.185 41.057 42.637 35.419 34.711\n",
      "  38.664 40.332 37.039 32.263 40.448]\n",
      " [35.655 38.506 34.141 39.581 42.484 38.76  42.81  44.054 37.045 37.096\n",
      "  39.943 41.985 37.749 33.875 42.072]\n",
      " [34.646 37.408 32.782 38.431 41.437 36.962 41.798 43.519 34.895 35.868\n",
      "  39.881 42.844 36.999 31.118 42.492]\n",
      " [33.05  35.926 30.271 36.319 38.683 35.458 40.051 43.128 33.647 33.636\n",
      "  37.334 41.087 35.778 28.716 42.17 ]\n",
      " [28.402 32.72  27.749 34.144 35.38  30.819 39.47  41.75  31.597 29.343\n",
      "  36.17  39.687 33.104 28.262 38.991]\n",
      " [27.378 34.772 29.642 36.072 38.642 33.976 40.007 41.416 32.63  30.82\n",
      "  36.157 39.393 35.167 29.581 40.735]\n",
      " [33.501 37.986 32.135 38.638 41.175 36.993 42.501 44.052 35.456 34.862\n",
      "  39.664 42.588 38.157 32.933 42.234]\n",
      " [35.63  39.728 32.778 39.004 43.108 38.964 41.779 43.835 35.919 36.745\n",
      "  40.393 42.514 39.25  32.396 42.499]\n",
      " [34.291 38.957 28.929 36.067 42.675 38.705 40.997 43.125 31.804 33.895\n",
      "  37.977 39.9   36.296 28.763 42.024]\n",
      " [31.043 37.294 29.533 36.103 40.108 36.276 42.602 41.918 34.758 32.587\n",
      "  37.534 39.49  35.973 31.449 42.784]\n",
      " [32.998 36.973 31.913 38.05  41.117 36.937 43.084 45.089 34.942 34.752\n",
      "  39.535 42.405 37.647 32.369 44.132]\n",
      " [33.189 37.466 30.206 37.371 40.622 36.543 40.867 44.062 32.337 34.23\n",
      "  39.16  42.567 37.512 30.04  42.34 ]\n",
      " [31.468 36.378 27.839 35.101 40.006 35.46  38.815 40.572 30.281 32.296\n",
      "  36.825 40.018 35.446 28.782 39.98 ]\n",
      " [30.664 35.257 27.254 34.393 38.373 33.861 37.935 39.724 28.276 31.664\n",
      "  35.605 39.076 33.842 27.257 39.106]\n",
      " [32.151 37.298 28.198 35.666 40.506 36.19  38.535 40.438 30.523 32.606\n",
      "  37.346 39.712 36.167 28.75  40.525]\n",
      " [32.7   37.252 31.106 37.599 38.793 34.408 41.386 44.384 33.723 34.346\n",
      "  40.957 43.394 39.671 32.146 42.544]\n",
      " [32.399 34.459 31.363 36.386 36.827 32.127 42.986 46.23  34.798 34.598\n",
      "  39.378 42.818 36.34  32.46  45.275]\n",
      " [28.858 31.136 30.578 34.066 31.407 28.449 42.146 41.802 34.634 31.66\n",
      "  36.307 37.707 29.882 32.349 42.716]\n",
      " [30.457 35.784 29.712 34.542 38.304 34.463 42.228 43.382 35.895 32.34\n",
      "  37.325 39.312 34.381 30.536 43.045]\n",
      " [32.817 35.62  29.522 37.766 39.4   35.594 43.187 44.297 36.042 33.679\n",
      "  38.092 41.394 35.151 31.228 44.654]\n",
      " [34.242 36.317 30.94  36.44  40.02  36.359 42.632 43.118 35.524 34.319\n",
      "  38.121 39.51  35.164 30.368 43.356]\n",
      " [33.153 36.201 29.533 36.869 39.448 36.328 42.517 43.985 34.845 33.257\n",
      "  38.721 40.876 34.863 30.814 43.067]\n",
      " [29.222 35.678 29.721 36.85  40.073 34.954 43.003 43.925 34.836 31.831\n",
      "  39.218 41.764 35.77  30.627 43.219]\n",
      " [31.936 35.266 29.589 36.744 39.21  35.035 41.35  43.778 33.913 33.626\n",
      "  38.654 41.57  34.351 29.873 42.528]\n",
      " [27.853 35.468 30.993 36.451 37.445 34.727 42.706 43.883 34.733 30.154\n",
      "  37.783 39.89  33.976 31.597 43.786]]\n",
      "\n",
      "Dates: 06/01/2024 - 06/30/2024\n",
      "\n",
      "Counties: ['04001', '04003', '04005', '04007', '04009', '04011', '04012', '04013', '04015', '04017', '04019', '04021', '04023', '04025', '04027']\n"
     ]
    }
   ],
   "source": [
    "raster_values_array = raster_values_at_centroids(attribute, date_range, centroids)\n",
    "\n",
    "print(\"Raster values in all counties in Arizona:\")\n",
    "print(raster_values_array)\n",
    "print(f\"\\nDates: {start_date_str} - {end_date_str}\")\n",
    "print(f\"\\nCounties: {all_counties_az}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Taken Up from PRISM Files\n",
    "\n",
    "The majority of the time spent running comes from fetching the files themselves rather than actually interpreting the raster data. However, the space has yet to be recorded. The following code takes in a basic file path and collects the amount of space all of the dates for those files takes up all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date as datetype\n",
    "from datetime import timedelta\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def generate_file_paths(\n",
    "    template: str, start_date: datetype, num_days: int\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate the file names\"\"\"\n",
    "    file_paths = []\n",
    "    # iterate through everyday\n",
    "    for i in range(num_days):\n",
    "        current_date = start_date + timedelta(days=i)\n",
    "        # format each date\n",
    "        formatted_date = current_date.strftime(\"%Y%m%d\")\n",
    "        file_path = template.replace(\"DATE\", formatted_date)\n",
    "        file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def format_size(size_in_bytes: int) -> str:\n",
    "    \"\"\"Format the file size as a string\"\"\"\n",
    "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n",
    "        # format based on the amount\n",
    "        if size_in_bytes < 1024:\n",
    "            return f\"{size_in_bytes:.2f} {unit}\"\n",
    "        size_in_bytes /= 1024\n",
    "\n",
    "\n",
    "def print_file_size(file_paths: List[str]):\n",
    "    \"\"\"Print the sum of all of the files sizes\"\"\"\n",
    "    file_sum = 0\n",
    "    # add up all of the file sizes\n",
    "    for f in file_paths:\n",
    "        file_path = Path(f)\n",
    "        file_size_bytes = file_path.stat().st_size\n",
    "        file_sum += file_size_bytes\n",
    "\n",
    "    formatted_size = format_size(file_sum)\n",
    "    print(f\"PRISM file size: {formatted_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISM file size: 34.09 MB\n"
     ]
    }
   ],
   "source": [
    "template = \"PRISM_ppt_provisional_4kmD2_DATE_bil.zip\"\n",
    "file_paths = generate_file_paths(template, start_date, TimeFrame.duration_days)\n",
    "\n",
    "print_file_size(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Temperature Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISM file size: 56.93 MB\n"
     ]
    }
   ],
   "source": [
    "template = \"PRISM_tmax_provisional_4kmD2_DATE_bil.zip\"\n",
    "file_paths = generate_file_paths(template, start_date, TimeFrame.duration_days)\n",
    "\n",
    "print_file_size(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size Analysis\n",
    "\n",
    "As shown by the file sizes for the precipitation against the maximum temperature files, the difference is quite large. The maximum temperature files take over 20 more MB of storage than the precipitation files. The likely reason is that maximum temperature has raster values for every single point on the raster grid, as each location has a maximum temperature of some value. Compare this with precipitation in which some locations do not receive any precipitation, leaving areas with 0s. The amount of space taken when fetching and downloading files is pretty significant for the range of a month. As for time, through this experimentation, it has been discovered that weak internet can drastically change the runtime for fetching the zip files from the PRISM website. In addition, having a large amount of files cached or having low storage space can also increase the time for downloading the files. In general, when running the ADRIO template for PRISM, ensure that the given machine has the storage to hold this amount of data and that the provided internet is decently strong."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
