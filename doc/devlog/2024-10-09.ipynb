{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# devlog 2024-10-09\n",
    "\n",
    "_Author: Tyler Coles_\n",
    "\n",
    "Methods for group-and-aggregate on time-series data.\n",
    "\n",
    "epymorph output data can be thought of as three-dimensional -- the axes are 1. time, 2. geospatial node, 3. simulation data values (which can include simulation state and transition information; aka compartments and events). A very common requirement in data processing is to be able to summarize the time axis of this data. For example, computing the sum of infections over the whole time series, or a monthly maximum infection for every month during the simulation.\n",
    "\n",
    "To determine the best approach, we generate some (suitably large) example data, group by calendar month, and compute the sum for each month. We compare by execution time and the simplicity of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates.shape=(7932,)\n",
      "values.shape=(7932, 3)\n",
      "['2020-01-23', '2020-01-23', '2020-01-24', '2020-01-24', '2020-01-25', '2020-01-25', '2020-01-26']\n",
      "[[16 17 18]\n",
      " [17 18 19]\n",
      " [18 19 20]\n",
      " [19 20 21]\n",
      " [20 21 22]\n",
      " [21 22 23]\n",
      " [22 23 24]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from epymorph.time import DateRange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from calendar import monthrange\n",
    "\n",
    "date_range = list(\n",
    "    DateRange(\n",
    "        date(2020, 1, 15),\n",
    "        date(2030, 11, 24),\n",
    "    )\n",
    ")\n",
    "\n",
    "days = len(date_range)\n",
    "tau_steps = 2\n",
    "\n",
    "dates = np.repeat(np.array(date_range, dtype=np.datetime64), repeats=tau_steps)\n",
    "values = np.column_stack(\n",
    "    [\n",
    "        # This array structure simulates multiple values per day\n",
    "        np.arange(days * tau_steps) + 0,  # e.g., this could be compartment S\n",
    "        np.arange(days * tau_steps) + 1,  # this could be the S->I event\n",
    "        np.arange(days * tau_steps) + 2,  # etc.\n",
    "        # I call this dimension, generically, the number of \"quantities\"\n",
    "    ]\n",
    ")\n",
    "quantities = values.shape[1]\n",
    "\n",
    "print(f\"{dates.shape=}\")\n",
    "print(f\"{values.shape=}\")\n",
    "print([str(x) for x in dates[16:23]])\n",
    "print(values[16:23, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_range_months=131\n"
     ]
    }
   ],
   "source": [
    "# Utility functions\n",
    "\n",
    "\n",
    "def count_months(d1: date, d2: date) -> int:\n",
    "    \"\"\"Compute the number of unique months included in a range of dates.\"\"\"\n",
    "    if d1 > d2:\n",
    "        d1, d2 = d2, d1\n",
    "    return (d2.year - d1.year) * 12 + (d2.month - d1.month) + 1\n",
    "\n",
    "\n",
    "date_range_months = count_months(date_range[0], date_range[-1])\n",
    "print(f\"{date_range_months=}\")\n",
    "\n",
    "\n",
    "# epi weeks: https://www.cmmcp.org/mosquito-surveillance-data/pages/epi-week-calendars-2008-2024\n",
    "\n",
    "\n",
    "def first_epi_day(year: int) -> pd.Timestamp:\n",
    "    first_saturday = pd.Timestamp(year, 1, 1) + pd.offsets.Week(weekday=5)\n",
    "    if first_saturday.day < 4:\n",
    "        first_saturday = first_saturday + pd.offsets.Week(weekday=5)\n",
    "    first_epi_day = first_saturday - pd.offsets.Week(weekday=6)\n",
    "    return first_epi_day\n",
    "\n",
    "\n",
    "def epi_week(check_date: date) -> tuple[int, int]:\n",
    "    d = pd.Timestamp(check_date.year, check_date.month, check_date.day)\n",
    "    last_year_day1 = first_epi_day(d.year - 1)\n",
    "    this_year_day1 = first_epi_day(d.year)\n",
    "    next_year_day1 = first_epi_day(d.year + 1)\n",
    "    if d < this_year_day1:\n",
    "        # in last years' epi weeks\n",
    "        origin = last_year_day1\n",
    "        year = d.year - 1\n",
    "    elif d >= next_year_day1:\n",
    "        # in next years' epi weeks\n",
    "        origin = next_year_day1\n",
    "        year = d.year + 1\n",
    "    else:\n",
    "        # in this years' epi weeks\n",
    "        origin = this_year_day1\n",
    "        year = d.year\n",
    "    return year, (d - origin).days // 7 + 1\n",
    "\n",
    "\n",
    "def epi_week_start(epi_week: tuple[int, int]) -> pd.Timestamp:\n",
    "    year, week = epi_week\n",
    "    day1 = first_epi_day(year)\n",
    "    return day1 + pd.offsets.Week(n=week - 1)\n",
    "\n",
    "\n",
    "# %timeit first_epi_day(2021)\n",
    "# %timeit epi_week(date(2021, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: computing monthly sums\n",
    "\n",
    "### Approach 1: a basic Python loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.2 ms ± 101 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  561,   595,   629],\n",
       "       [ 3625,  3683,  3741],\n",
       "       [ 7595,  7657,  7719],\n",
       "       [11010, 11070, 11130],\n",
       "       [15159, 15221, 15283],\n",
       "       [18330, 18390, 18450],\n",
       "       [22723, 22785, 22847],\n",
       "       [26567, 26629, 26691],\n",
       "       [29370, 29430, 29490],\n",
       "       [34131, 34193, 34255]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_1():\n",
    "    initial_year = date_range[0].year\n",
    "    months = count_months(date_range[0], date_range[-1])\n",
    "    result = np.zeros((months, quantities), dtype=values.dtype)\n",
    "    for dnp, v in zip(dates, values):\n",
    "        d = dnp.astype(\"object\")\n",
    "        t = (d.year - initial_year) * 12 + d.month - 1\n",
    "        for q in range(quantities):\n",
    "            result[t, q] += v[q]\n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit calc_1()\n",
    "res1 = calc_1()\n",
    "res1[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Approach 2: Pandas resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ms ± 23.9 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  561,   595,   629],\n",
       "       [ 3625,  3683,  3741],\n",
       "       [ 7595,  7657,  7719],\n",
       "       [11010, 11070, 11130],\n",
       "       [15159, 15221, 15283],\n",
       "       [18330, 18390, 18450],\n",
       "       [22723, 22785, 22847],\n",
       "       [26567, 26629, 26691],\n",
       "       [29370, 29430, 29490],\n",
       "       [34131, 34193, 34255]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#cookbook-resample\n",
    "\n",
    "\n",
    "def calc_2():\n",
    "    data_df = pd.DataFrame(index=pd.to_datetime(dates), data=values)\n",
    "    result_df = data_df.resample(rule=\"MS\").agg(func=\"sum\")\n",
    "    return result_df.to_numpy()\n",
    "\n",
    "\n",
    "%timeit calc_2()\n",
    "res2 = calc_2()\n",
    "res2[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: numpy, reshape to add a days-in-the-month axis, sum all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 μs ± 3.31 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  561,   595,   629],\n",
       "       [ 3625,  3683,  3741],\n",
       "       [ 7595,  7657,  7719],\n",
       "       [11010, 11070, 11130],\n",
       "       [15159, 15221, 15283],\n",
       "       [18330, 18390, 18450],\n",
       "       [22723, 22785, 22847],\n",
       "       [26567, 26629, 26691],\n",
       "       [29370, 29430, 29490],\n",
       "       [34131, 34193, 34255]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_3():\n",
    "    AGG_FN = np.sum\n",
    "    ZERO = 0\n",
    "    initial_date = date_range[0]\n",
    "    final_date = date_range[-1]\n",
    "    n = len(values)\n",
    "    months = count_months(initial_date, final_date)\n",
    "    matrix = np.full((months, 31 * tau_steps, quantities), ZERO, dtype=values.dtype)\n",
    "    i, m = 0, 0\n",
    "    while i < n:\n",
    "        curr_date = dates[i].astype(\"object\")\n",
    "        _, month_len = monthrange(curr_date.year, curr_date.month)\n",
    "        last_date = min(final_date, date(curr_date.year, curr_date.month, month_len))\n",
    "        days_this_month = (last_date.day - curr_date.day) + 1\n",
    "        j = i + (days_this_month * tau_steps)\n",
    "        w = (curr_date.day - 1) * tau_steps\n",
    "        z = w + days_this_month * tau_steps\n",
    "        matrix[m, w:z, :] = values[i:j, :]\n",
    "        i, m = j, m + 1\n",
    "    return AGG_FN(matrix, axis=1)\n",
    "\n",
    "\n",
    "%timeit calc_3()\n",
    "res3 = calc_3()\n",
    "res3[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 4: numpy, compute sum for each month and accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678 μs ± 7.32 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  561,   595,   629],\n",
       "       [ 3625,  3683,  3741],\n",
       "       [ 7595,  7657,  7719],\n",
       "       [11010, 11070, 11130],\n",
       "       [15159, 15221, 15283],\n",
       "       [18330, 18390, 18450],\n",
       "       [22723, 22785, 22847],\n",
       "       [26567, 26629, 26691],\n",
       "       [29370, 29430, 29490],\n",
       "       [34131, 34193, 34255]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy: month-by-month\n",
    "\n",
    "\n",
    "def calc_4():\n",
    "    initial_date = date_range[0]\n",
    "    final_date = date_range[-1]\n",
    "    n = len(values)\n",
    "    months = count_months(initial_date, final_date)\n",
    "    result = np.empty((months, quantities), dtype=values.dtype)\n",
    "    i, m = 0, 0\n",
    "    while i < n:\n",
    "        curr_date = dates[i].astype(\"object\")\n",
    "        _, month_len = monthrange(curr_date.year, curr_date.month)\n",
    "        last_date = min(final_date, date(curr_date.year, curr_date.month, month_len))\n",
    "        days_this_month = (last_date.day - curr_date.day) + 1\n",
    "        j = i + (days_this_month * tau_steps)\n",
    "        result[m, :] = values[i:j, :].sum(axis=0)\n",
    "        i, m = j, m + 1\n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit calc_4()\n",
    "res4 = calc_4()\n",
    "res4[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we get the same answer for all approaches.\n",
    "(\n",
    "    res1.shape == (date_range_months, quantities)\n",
    "    and np.array_equal(res1, res2)\n",
    "    and np.array_equal(res1, res3)\n",
    "    and np.array_equal(res1, res4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: computing weekly sums\n",
    "\n",
    "### Approach 1: pandas resample\n",
    "\n",
    "This approach has the unfortunate side-effect of dropping partial weeks from the beginning and end of the time data timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.51 ms ± 40.2 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatetimeIndex(['2020-01-19', '2020-01-26', '2020-02-02', '2020-02-09',\n",
       "                '2020-02-16', '2020-02-23', '2020-03-01', '2020-03-08',\n",
       "                '2020-03-15', '2020-03-22',\n",
       "                ...\n",
       "                '2030-09-22', '2030-09-29', '2030-10-06', '2030-10-13',\n",
       "                '2030-10-20', '2030-10-27', '2030-11-03', '2030-11-10',\n",
       "                '2030-11-17', '2030-11-24'],\n",
       "               dtype='datetime64[s]', length=567, freq='W-SUN'),\n",
       " array([[    45,     55,     65],\n",
       "        [   231,    245,    259],\n",
       "        [   427,    441,    455],\n",
       "        ...,\n",
       "        [110579, 110593, 110607],\n",
       "        [110775, 110789, 110803],\n",
       "        [ 95106,  95118,  95130]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_weekly_pandas():\n",
    "    data_df = pd.DataFrame(index=pd.to_datetime(dates), data=values)\n",
    "    # Calc sum by weekday where weeks start on Sundays\n",
    "    result_df = data_df.resample(rule=pd.offsets.Week(weekday=6)).agg(func=\"sum\")\n",
    "    # display(result_df)\n",
    "    # Also you get the new dates automatically...\n",
    "    return result_df.index, result_df.to_numpy()\n",
    "\n",
    "\n",
    "%timeit calc_weekly_pandas()\n",
    "calc_weekly_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: pandas groupby on week column\n",
    "\n",
    "Pandas' resample function is powerful, but it only supports so many timeframe rules out of the box. \"Epi week\" is a very specific definition for the weeks in the year that attempts to standardize weekly comparisons. Maybe we could define a custom Pandas Offset class for this, but it's simpler to use a column which describes the group each row belongs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673 ms ± 2.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatetimeIndex(['2020-01-12', '2020-01-19', '2020-01-26', '2020-02-02',\n",
       "                '2020-02-09', '2020-02-16', '2020-02-23', '2020-03-01',\n",
       "                '2020-03-08', '2020-03-15',\n",
       "                ...\n",
       "                '2030-09-15', '2030-09-22', '2030-09-29', '2030-10-06',\n",
       "                '2030-10-13', '2030-10-20', '2030-10-27', '2030-11-03',\n",
       "                '2030-11-10', '2030-11-17'],\n",
       "               dtype='datetime64[ns]', name='epiweek', length=567, freq=None),\n",
       " array([[    28,     36,     44],\n",
       "        [   203,    217,    231],\n",
       "        [   399,    413,    427],\n",
       "        ...,\n",
       "        [110551, 110565, 110579],\n",
       "        [110747, 110761, 110775],\n",
       "        [110943, 110957, 110971]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_epiweekly_pandas():\n",
    "    data_df = pd.DataFrame(index=pd.to_datetime(dates), data=values)\n",
    "    data_df[\"epiweek\"] = data_df.index.map(epi_week)\n",
    "    # Calc sum by epi week\n",
    "    result_df = data_df.groupby(\"epiweek\").agg(func=\"sum\")\n",
    "    # Also we can also return the new dates...\n",
    "    return result_df.index.map(epi_week_start), result_df.to_numpy()\n",
    "\n",
    "\n",
    "%timeit calc_epiweekly_pandas()\n",
    "calc_epiweekly_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "While the numpy versions are somewhat faster, they are much more challenging to write and need to be specially designed to deal with different time periods. It's not obvious how to adjust the logic to work with arbitrary time periods like epi weeks.\n",
    "\n",
    "On the other hand, Pandas is not tragically slow -- faster than I was expecting -- and it's very obvious how to extend it for highly arbitrary time period definitions. Pandas resample behavior is a little esoteric, but adding a column on which to group is very simple. That's a clear winner in this situation.\n",
    "\n",
    "Note: I also tested using polars for this as a curiosity. It was about 10x faster, but didn't produce the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: unit tests for the epi week functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class EpiWeeksTest(unittest.TestCase):\n",
    "    def test_first_epi_day(self):\n",
    "        self.assertEqual(first_epi_day(2020), pd.Timestamp(2019, 12, 29))\n",
    "        self.assertEqual(first_epi_day(2021), pd.Timestamp(2021, 1, 3))\n",
    "        self.assertEqual(first_epi_day(2022), pd.Timestamp(2022, 1, 2))\n",
    "        self.assertEqual(first_epi_day(2023), pd.Timestamp(2023, 1, 1))\n",
    "        self.assertEqual(first_epi_day(2024), pd.Timestamp(2023, 12, 31))\n",
    "        self.assertEqual(first_epi_day(2025), pd.Timestamp(2024, 12, 29))\n",
    "\n",
    "    def test_epi_week(self):\n",
    "        self.assertEqual(epi_week(date(2021, 1, 1)), (2020, 53))\n",
    "        self.assertEqual(epi_week(date(2021, 1, 2)), (2020, 53))\n",
    "        self.assertEqual(epi_week(date(2021, 1, 3)), (2021, 1))\n",
    "\n",
    "        self.assertEqual(epi_week(date(2024, 1, 1)), (2024, 1))\n",
    "        self.assertEqual(epi_week(date(2024, 1, 6)), (2024, 1))\n",
    "        self.assertEqual(epi_week(date(2024, 1, 7)), (2024, 2))\n",
    "        self.assertEqual(epi_week(date(2024, 3, 14)), (2024, 11))\n",
    "        self.assertEqual(epi_week(date(2024, 12, 28)), (2024, 52))\n",
    "        self.assertEqual(epi_week(date(2024, 12, 29)), (2025, 1))\n",
    "        self.assertEqual(epi_week(date(2024, 12, 31)), (2025, 1))\n",
    "\n",
    "\n",
    "# Run tests here in the notebook\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTests(unittest.TestLoader().loadTestsFromTestCase(EpiWeeksTest))\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
